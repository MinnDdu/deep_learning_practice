{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsHGeerFxSGd8luQtBJs1k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinnDdu/deep_learning_practice/blob/main/cat_dog_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8oSXLjRAmDX",
        "outputId": "97cb87c9-bd8b-4e80-8464-c4bda3f69e82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading dogs-vs-cats-redux-kernels-edition.zip to /content\n",
            " 98% 796M/814M [00:07<00:00, 124MB/s]\n",
            "100% 814M/814M [00:07<00:00, 114MB/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'\n",
        "\n",
        "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q dogs-vs-cats-redux-kernels-edition.zip"
      ],
      "metadata": {
        "id": "8yGGD-fxBEMh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q train.zip -d ."
      ],
      "metadata": {
        "id": "zhu7QVnJBENh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "\n",
        "print(len(os.listdir('/content/train/')))\n",
        "# os.listdir() -> list안에 파일들을 담아줌 [파일명1, 파일명2,...]\n",
        "\n",
        "# bug fix - colab에선 파이썬 명령어로 경로 만들어야 클래스가 하나 더 생기는 일 방지\n",
        "os.mkdir('/content/dataset')\n",
        "os.mkdir('/content/dataset/cat')\n",
        "os.mkdir('/content/dataset/dog')\n",
        "\n",
        "# 파일을 숫자로 변환\n",
        "# 1. opencv library로 반복문으로 이미지 숫자화\n",
        "# 2. tf.keras 이용해서 한번에 처리\n",
        "for i in os.listdir('/content/train/'):\n",
        "    # i는 'cat01.jpg' ...\n",
        "    # shutil.copyfile('어떤경로의 파일을', '어떤 경로에다가 복사')\n",
        "    if 'cat' in i:\n",
        "        shutil.copyfile('/content/train/' + i, '/content/dataset/cat/' + i)\n",
        "    if 'dog' in i:\n",
        "        shutil.copyfile('/content/train/' + i, '/content/dataset/dog/' + i)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz8yRYjKBudk",
        "outputId": "4be2baca-2ecd-42c9-8615-2b9f55afbc2e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/dataset/', \n",
        "    image_size=(64,64), \n",
        "    batch_size=32, # 이미지 전부 한번에 epoch에 넣지 않고 batch 숫자만큼 넣고 w계산, 갱신\n",
        "    subset='training',\n",
        "    validation_split=0.2, # 데이터의 80%를 training dataset으로 감\n",
        "    seed=1234\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/dataset/', \n",
        "    image_size=(64,64), \n",
        "    batch_size=32, # 이미지 전부 한번에 epoch에 넣지 않고 batch 숫자만큼 넣고 w계산, 갱신\n",
        "    subset='validation',\n",
        "    validation_split=0.2, # 데이터의 20%를 validation dataset으로 감\n",
        "    seed=1234\n",
        ")\n",
        "# train_ds의 결과 -> ((xxxxxx... - 이미지 숫자화됨), (yyyyyy... - 0또는1))\n",
        "\n",
        "# image classification 에선 그 전에 파일들을 나누어 눠야함 \n",
        "# Ex) cat file, dog file 만들고 그 사진들 넣기 - 이미지 분류 딥러닝 국룰\n",
        "\n",
        "print(train_ds)\n",
        "\n",
        "# tuning - 레이어 더 늘리기, \n",
        "# 이미지(데이터) 전처리가 중요! -> 데이터 양 올리기 or 데이터 질 올리기\n",
        "def preprocessing(i, answer):\n",
        "    i = tf.cast(i/255.0, tf.float32)\n",
        "    return i, answer\n",
        "\n",
        "train_ds = train_ds.map(preprocessing)\n",
        "val_ds = train_ds.map(preprocessing)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i, answer in train_ds.take(1): \n",
        "    # train_ds는 batch dataset이라는 일종의 자료형 take(1) -> 하나의 batch 가져옴\n",
        "    print(i)\n",
        "    print(answer)\n",
        "    # plt.imshow(i[0].numpy().astype('uint8')) # i[0]은 tensor -> numpy()로 넘파이형으로 캐스팅\n",
        "    # plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Rb5bIF1jEOii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 딥러닝 모델 만들기\n",
        "\n",
        "# Image Augmentation - 이미지 증강 -> 기존 이미지 데이터를 약간 확대/이동/뒤집기 해서 새로운 데이터같이 이용\n",
        "# 방법1 -> 증강된 데이터 사본 생성\n",
        "# 방법2 -> 모델에 넣기 전에 이미지 증강\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    # 모델에 넣기 전에 이미지 증강\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal', input_shape=(64, 64, 3)), # 확률로 데이터 가로로 뒤집기\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1), # 데이터 회전\n",
        "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1), # 데이터 줌\n",
        "    # Ex) epoch이 10 -> 기존) 같은데이터 10번 / 증강) 약간다른 데이터 10번\n",
        "\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    tf.keras.layers.Dropout(0.2), # overfitting 완화 -> dropout 레이어 - 윗레이어 노드를 일부 제거\n",
        "    \n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2), # overfitting 완화 -> dropout 레이어 - 윗레이어 노드를 일부 제거\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid') # binary crossentropy는 마지막 sigmoid 필요\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=5)\n",
        "# train_ds ((이미지들), (정답들)) 형태\n",
        "    \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6mmSz3O8p3U",
        "outputId": "51825aa9-77b7-4dcb-8f66-e48d374e9f06"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " random_flip_1 (RandomFlip)  (None, 64, 64, 3)         0         \n",
            "                                                                 \n",
            " random_rotation_1 (RandomRo  (None, 64, 64, 3)        0         \n",
            " tation)                                                         \n",
            "                                                                 \n",
            " random_zoom_1 (RandomZoom)  (None, 64, 64, 3)         0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 32, 32, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 32, 32, 128)       36992     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 16, 16, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               524416    \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 636,225\n",
            "Trainable params: 636,225\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "625/625 [==============================] - 473s 666ms/step - loss: 0.6694 - accuracy: 0.5826 - val_loss: 1.2225 - val_accuracy: 0.4997\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 393s 629ms/step - loss: 0.5972 - accuracy: 0.6831 - val_loss: 2.1887 - val_accuracy: 0.4997\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 394s 629ms/step - loss: 0.5445 - accuracy: 0.7223 - val_loss: 1.0406 - val_accuracy: 0.4997\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 387s 619ms/step - loss: 0.5186 - accuracy: 0.7441 - val_loss: 0.9434 - val_accuracy: 0.4997\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 392s 628ms/step - loss: 0.4847 - accuracy: 0.7679 - val_loss: 0.8778 - val_accuracy: 0.4997\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f678066f610>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}