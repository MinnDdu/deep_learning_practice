{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrJhO4LEt0JE81A2xpAiDd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinnDdu/deep_learning_practice/blob/main/cat_dog_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8oSXLjRAmDX",
        "outputId": "97cb87c9-bd8b-4e80-8464-c4bda3f69e82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading dogs-vs-cats-redux-kernels-edition.zip to /content\n",
            " 98% 796M/814M [00:07<00:00, 124MB/s]\n",
            "100% 814M/814M [00:07<00:00, 114MB/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'\n",
        "\n",
        "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q dogs-vs-cats-redux-kernels-edition.zip"
      ],
      "metadata": {
        "id": "8yGGD-fxBEMh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q train.zip -d ."
      ],
      "metadata": {
        "id": "zhu7QVnJBENh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "\n",
        "print(len(os.listdir('/content/train/')))\n",
        "# os.listdir() -> list안에 파일들을 담아줌 [파일명1, 파일명2,...]\n",
        "\n",
        "# bug fix - colab에선 파이썬 명령어로 경로 만들어야 클래스가 하나 더 생기는 일 방지\n",
        "os.mkdir('/content/dataset')\n",
        "os.mkdir('/content/dataset/cat')\n",
        "os.mkdir('/content/dataset/dog')\n",
        "\n",
        "# 파일을 숫자로 변환\n",
        "# 1. opencv library로 반복문으로 이미지 숫자화\n",
        "# 2. tf.keras 이용해서 한번에 처리\n",
        "for i in os.listdir('/content/train/'):\n",
        "    # i는 'cat01.jpg' ...\n",
        "    # shutil.copyfile('어떤경로의 파일을', '어떤 경로에다가 복사')\n",
        "    if 'cat' in i:\n",
        "        shutil.copyfile('/content/train/' + i, '/content/dataset/cat/' + i)\n",
        "    if 'dog' in i:\n",
        "        shutil.copyfile('/content/train/' + i, '/content/dataset/dog/' + i)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz8yRYjKBudk",
        "outputId": "4be2baca-2ecd-42c9-8615-2b9f55afbc2e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/dataset/', \n",
        "    image_size=(64,64), \n",
        "    batch_size=32, # 이미지 전부 한번에 epoch에 넣지 않고 batch 숫자만큼 넣고 w계산, 갱신\n",
        "    subset='training',\n",
        "    validation_split=0.2, # 데이터의 80%를 training dataset으로 감\n",
        "    seed=1234\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/dataset/', \n",
        "    image_size=(64,64), \n",
        "    batch_size=32, # 이미지 전부 한번에 epoch에 넣지 않고 batch 숫자만큼 넣고 w계산, 갱신\n",
        "    subset='validation',\n",
        "    validation_split=0.2, # 데이터의 20%를 validation dataset으로 감\n",
        "    seed=1234\n",
        ")\n",
        "# train_ds의 결과 -> ((xxxxxx... - 이미지 숫자화됨), (yyyyyy... - 0또는1))\n",
        "\n",
        "# image classification 에선 그 전에 파일들을 나누어 눠야함 \n",
        "# Ex) cat file, dog file 만들고 그 사진들 넣기 - 이미지 분류 딥러닝 국룰\n",
        "\n",
        "print(train_ds)\n",
        "\n",
        "# tuning - 레이어 더 늘리기, \n",
        "# 이미지(데이터) 전처리가 중요! -> 데이터 양 올리기 or 데이터 질 올리기\n",
        "def preprocessing(i, answer):\n",
        "    i = tf.cast(i/255.0, tf.float32)\n",
        "    return i, answer\n",
        "\n",
        "train_ds = train_ds.map(preprocessing)\n",
        "val_ds = train_ds.map(preprocessing)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i, answer in train_ds.take(1): \n",
        "    # train_ds는 batch dataset이라는 일종의 자료형 take(1) -> 하나의 batch 가져옴\n",
        "    print(i)\n",
        "    print(answer)\n",
        "    # plt.imshow(i[0].numpy().astype('uint8')) # i[0]은 tensor -> numpy()로 넘파이형으로 캐스팅\n",
        "    # plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb5bIF1jEOii",
        "outputId": "0c137aed-bb49-4efe-e7ae-bea288e088e5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n",
            "tf.Tensor(\n",
            "[[[[0.08425054 0.02934857 0.02542701]\n",
            "   [0.0788603  0.02395833 0.02003676]\n",
            "   [0.09209559 0.04895834 0.03327206]\n",
            "   ...\n",
            "   [0.06710516 0.02360026 0.00803654]\n",
            "   [0.07450981 0.01960784 0.01568628]\n",
            "   [0.00392923 0.00803654 0.00392923]]\n",
            "\n",
            "  [[0.1010972  0.0501168  0.02658739]\n",
            "   [0.119267   0.06828661 0.0447572 ]\n",
            "   [0.06590265 0.03845167 0.01492226]\n",
            "   ...\n",
            "   [0.07071079 0.02720588 0.01164216]\n",
            "   [0.06977443 0.01487247 0.0109509 ]\n",
            "   [0.00349839 0.01146408 0.00509153]]\n",
            "\n",
            "  [[0.09571078 0.04473039 0.01335784]\n",
            "   [0.09761029 0.0466299  0.01525735]\n",
            "   [0.07900965 0.066142   0.03922909]\n",
            "   ...\n",
            "   [0.07178692 0.02703546 0.01188726]\n",
            "   [0.0753753  0.02147863 0.01722197]\n",
            "   [0.00857843 0.01602137 0.00982307]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.3947572  0.32857114 0.24108073]\n",
            "   [0.46586245 0.3835095  0.26279873]\n",
            "   [0.5416322  0.4666322  0.34874004]\n",
            "   ...\n",
            "   [0.46569967 0.29682714 0.0887389 ]\n",
            "   [0.37026656 0.20948224 0.0077742 ]\n",
            "   [0.4407437  0.29987362 0.05557215]]\n",
            "\n",
            "  [[0.48482114 0.40479666 0.29657438]\n",
            "   [0.51422524 0.4201076  0.27317134]\n",
            "   [0.49564952 0.43633577 0.31452206]\n",
            "   ...\n",
            "   [0.45350987 0.29272556 0.07311773]\n",
            "   [0.45362094 0.2897729  0.09197878]\n",
            "   [0.44724074 0.3043486  0.08106426]]\n",
            "\n",
            "  [[0.50129825 0.42721546 0.31569585]\n",
            "   [0.5409371  0.47267157 0.33688724]\n",
            "   [0.3788737  0.31072688 0.1809666 ]\n",
            "   ...\n",
            "   [0.45226717 0.29503676 0.06450291]\n",
            "   [0.40211588 0.28054726 0.05959138]\n",
            "   [0.36742684 0.234645   0.05584597]]]\n",
            "\n",
            "\n",
            " [[[0.21224533 0.24030043 0.21281882]\n",
            "   [0.25968328 0.35149837 0.28968674]\n",
            "   [0.23468712 0.3047727  0.24202761]\n",
            "   ...\n",
            "   [0.5584243  0.7282772  0.50805664]\n",
            "   [0.5104167  0.67634803 0.47965688]\n",
            "   [0.5078345  0.68430513 0.46861884]]\n",
            "\n",
            "  [[0.25026998 0.32710823 0.27319622]\n",
            "   [0.16403474 0.25218004 0.18261719]\n",
            "   [0.17885742 0.2684781  0.18494754]\n",
            "   ...\n",
            "   [0.5279192  0.68086034 0.4573309 ]\n",
            "   [0.5071347  0.65717965 0.45512888]\n",
            "   [0.4865598  0.6630304  0.44734412]]\n",
            "\n",
            "  [[0.26820427 0.34848633 0.28246304]\n",
            "   [0.25512886 0.29269013 0.22800149]\n",
            "   [0.38479245 0.43947896 0.35697284]\n",
            "   ...\n",
            "   [0.47438726 0.6682598  0.4125    ]\n",
            "   [0.45499867 0.6449496  0.41664082]\n",
            "   [0.47118375 0.64765435 0.43196806]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.5489947  0.47014686 0.40326574]\n",
            "   [0.5503849  0.46976104 0.38483456]\n",
            "   [0.5905599  0.50649124 0.4409888 ]\n",
            "   ...\n",
            "   [0.61251915 0.63558614 0.5842697 ]\n",
            "   [0.616794   0.6524663  0.56972176]\n",
            "   [0.59027743 0.5977529  0.532802  ]]\n",
            "\n",
            "  [[0.4929477  0.41059473 0.33608493]\n",
            "   [0.43450233 0.3521494  0.2776396 ]\n",
            "   [0.6277708  0.54541785 0.47090802]\n",
            "   ...\n",
            "   [0.62132543 0.6487764  0.5860313 ]\n",
            "   [0.3396781  0.39180645 0.31198204]\n",
            "   [0.49007735 0.51752836 0.4469401 ]]\n",
            "\n",
            "  [[0.50531363 0.4229607  0.3484509 ]\n",
            "   [0.43097234 0.3486194  0.2741096 ]\n",
            "   [0.5894234  0.5070705  0.4325607 ]\n",
            "   ...\n",
            "   [0.6366527  0.66339904 0.5956294 ]\n",
            "   [0.4930913  0.54220283 0.47806948]\n",
            "   [0.55831707 0.5954494  0.52032685]]]\n",
            "\n",
            "\n",
            " [[[0.81960785 0.7490196  0.654902  ]\n",
            "   [0.83302695 0.7624387  0.6683211 ]\n",
            "   [0.8235811  0.760836   0.6627968 ]\n",
            "   ...\n",
            "   [0.26058134 0.2092333  0.0844784 ]\n",
            "   [0.28349417 0.20300819 0.10452857]\n",
            "   [0.28327397 0.19222005 0.10361711]]\n",
            "\n",
            "  [[0.8235294  0.7529412  0.65882355]\n",
            "   [0.82438725 0.753799   0.6596814 ]\n",
            "   [0.8392157  0.7764706  0.6784314 ]\n",
            "   ...\n",
            "   [0.2908184  0.21420036 0.09581418]\n",
            "   [0.29744372 0.21901233 0.11925743]\n",
            "   [0.2927313  0.21514629 0.12102865]]\n",
            "\n",
            "  [[0.8235294  0.7531958  0.65856886]\n",
            "   [0.8325655  0.76231235 0.6675245 ]\n",
            "   [0.8392157  0.7764706  0.6780158 ]\n",
            "   ...\n",
            "   [0.34663755 0.24908854 0.13131893]\n",
            "   [0.294807   0.2156652  0.1144761 ]\n",
            "   [0.27202052 0.20315756 0.10633425]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.8113358  0.5721201  0.309375  ]\n",
            "   [0.78499156 0.5457759  0.28303078]\n",
            "   [0.8040307  0.56481504 0.30206993]\n",
            "   ...\n",
            "   [0.8436887  0.6395221  0.4115809 ]\n",
            "   [0.85076785 0.6468463  0.4193953 ]\n",
            "   [0.88410693 0.6781116  0.46062922]]\n",
            "\n",
            "  [[0.80036193 0.5611462  0.29840112]\n",
            "   [0.8310049  0.5917892  0.3290441 ]\n",
            "   [0.7909926  0.5556985  0.2733456 ]\n",
            "   ...\n",
            "   [0.8687002  0.66453356 0.43659237]\n",
            "   [0.7854607  0.58153915 0.35408816]\n",
            "   [0.89033014 0.68990695 0.47569126]]\n",
            "\n",
            "  [[0.78590685 0.5466912  0.2917892 ]\n",
            "   [0.7966127  0.557397   0.30249503]\n",
            "   [0.8096201  0.5586397  0.30765933]\n",
            "   ...\n",
            "   [0.88277805 0.65888095 0.39662609]\n",
            "   [0.8738971  0.65906864 0.43125   ]\n",
            "   [0.8606503  0.65832186 0.46212086]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.55070466 0.5287377  0.44246325]\n",
            "   [0.5453125  0.5453125  0.45119485]\n",
            "   [0.5490021  0.54508054 0.47449234]\n",
            "   ...\n",
            "   [0.5322522  0.5676076  0.5949054 ]\n",
            "   [0.5332721  0.60070467 0.66191787]\n",
            "   [0.49268296 0.51933736 0.6071744 ]]\n",
            "\n",
            "  [[0.5505821  0.5286152  0.44234067]\n",
            "   [0.5419424  0.5419424  0.44782475]\n",
            "   [0.5607537  0.55683213 0.47447917]\n",
            "   ...\n",
            "   [0.5608456  0.60398287 0.6273897 ]\n",
            "   [0.5197749  0.5872075  0.64842075]\n",
            "   [0.5722426  0.596538   0.684375  ]]\n",
            "\n",
            "  [[0.55023193 0.5286152  0.44234067]\n",
            "   [0.5419424  0.5419424  0.44782475]\n",
            "   [0.5607537  0.5607537  0.4587929 ]\n",
            "   ...\n",
            "   [0.5808426  0.63955724 0.65906864]\n",
            "   [0.46063998 0.5280726  0.59022266]\n",
            "   [0.60677516 0.6331976  0.72243077]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.46314338 0.4239277  0.32588848]\n",
            "   [0.46397945 0.42476377 0.32672453]\n",
            "   [0.48801628 0.44487903 0.3350751 ]\n",
            "   ...\n",
            "   [0.500472   0.48478574 0.44949162]\n",
            "   [0.4935791  0.47789282 0.4425987 ]\n",
            "   [0.47023806 0.4545518  0.41925767]]\n",
            "\n",
            "  [[0.44864407 0.4329578  0.29012692]\n",
            "   [0.4498468  0.43416053 0.29132965]\n",
            "   [0.4823441  0.4431284  0.3030855 ]\n",
            "   ...\n",
            "   [0.49644607 0.4807598  0.44546568]\n",
            "   [0.48538604 0.46969974 0.43440562]\n",
            "   [0.47999388 0.4643076  0.4290135 ]]\n",
            "\n",
            "  [[0.41813725 0.39148283 0.29733455]\n",
            "   [0.4588848  0.41029412 0.3075674 ]\n",
            "   [0.48400736 0.4408701  0.3153799 ]\n",
            "   ...\n",
            "   [0.4958465  0.48016024 0.4448661 ]\n",
            "   [0.48180148 0.4661152  0.4308211 ]\n",
            "   [0.4745098  0.45882353 0.42352942]]]\n",
            "\n",
            "\n",
            " [[[0.2490476  0.21543854 0.14540178]\n",
            "   [0.29543504 0.26182598 0.19178921]\n",
            "   [0.32882965 0.2856924  0.19941789]\n",
            "   ...\n",
            "   [0.43974537 0.42798066 0.29072577]\n",
            "   [0.416889   0.416889   0.27571255]\n",
            "   [0.3959559  0.3959559  0.2547794 ]]\n",
            "\n",
            "  [[0.30463412 0.27718315 0.16345765]\n",
            "   [0.29375    0.266299   0.15257353]\n",
            "   [0.348398   0.30918232 0.20329997]\n",
            "   ...\n",
            "   [0.4425068  0.43074208 0.30128676]\n",
            "   [0.43465766 0.43465766 0.2934812 ]\n",
            "   [0.40965864 0.40965864 0.26848215]]\n",
            "\n",
            "  [[0.31354168 0.28275123 0.19080882]\n",
            "   [0.3204044  0.28903186 0.19883579]\n",
            "   [0.35741878 0.32212466 0.20839916]\n",
            "   ...\n",
            "   [0.47193962 0.4590198  0.33796746]\n",
            "   [0.44950095 0.44775462 0.30716026]\n",
            "   [0.41934526 0.41759896 0.2770046 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.11200071 0.09169251 0.07012389]\n",
            "   [0.11648548 0.11713772 0.08613281]\n",
            "   [0.08008578 0.08342525 0.0520527 ]\n",
            "   ...\n",
            "   [0.07274649 0.11183962 0.0806509 ]\n",
            "   [0.06227668 0.08580609 0.07796296]\n",
            "   [0.06158088 0.08511029 0.07726716]]\n",
            "\n",
            "  [[0.08124115 0.06777655 0.06943096]\n",
            "   [0.07214379 0.07998693 0.07379821]\n",
            "   [0.08121936 0.0890625  0.07503064]\n",
            "   ...\n",
            "   [0.05496323 0.07447917 0.05110294]\n",
            "   [0.05398978 0.06183292 0.05791135]\n",
            "   [0.05655637 0.06439951 0.06047794]]\n",
            "\n",
            "  [[0.07720588 0.06936274 0.07328431]\n",
            "   [0.06333511 0.05549197 0.05941354]\n",
            "   [0.06658792 0.08227419 0.08619576]\n",
            "   ...\n",
            "   [0.04892769 0.06838235 0.05275735]\n",
            "   [0.0627451  0.06666667 0.04705882]\n",
            "   [0.06443015 0.06835172 0.04874387]]]\n",
            "\n",
            "\n",
            " [[[0.41278148 0.57748735 0.4206246 ]\n",
            "   [0.47083333 0.6394608  0.46213236]\n",
            "   [0.48507008 0.6458544  0.4811485 ]\n",
            "   ...\n",
            "   [0.4854224  0.6343195  0.47329006]\n",
            "   [0.507891   0.6686753  0.50396943]\n",
            "   [0.45418006 0.6091797  0.4510589 ]]\n",
            "\n",
            "  [[0.4778282  0.6425341  0.48567134]\n",
            "   [0.49417892 0.6628064  0.48547795]\n",
            "   [0.5428309  0.6800858  0.52322304]\n",
            "   ...\n",
            "   [0.45839652 0.6196155  0.45447877]\n",
            "   [0.42475298 0.5855373  0.4208314 ]\n",
            "   [0.4918658  0.6625517  0.48883846]]\n",
            "\n",
            "  [[0.4771829  0.6379672  0.4654182 ]\n",
            "   [0.42346624 0.5842505  0.41170153]\n",
            "   [0.50838697 0.6691713  0.51230854]\n",
            "   ...\n",
            "   [0.53678    0.6939051  0.49831685]\n",
            "   [0.49351063 0.6346871  0.49351063]\n",
            "   [0.5005936  0.6551279  0.47069162]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.95526963 0.95134807 0.9317402 ]\n",
            "   [0.92267156 0.91875    0.89914215]\n",
            "   [0.9564166  0.95249504 0.9328872 ]\n",
            "   ...\n",
            "   [0.37170076 0.47746056 0.308588  ]\n",
            "   [0.3750517  0.48093405 0.3123066 ]\n",
            "   [0.4137638  0.51964617 0.3510187 ]]\n",
            "\n",
            "  [[0.95763445 0.9537129  0.93410504]\n",
            "   [0.9051605  0.9012389  0.8816311 ]\n",
            "   [0.9452206  0.941299   0.9216912 ]\n",
            "   ...\n",
            "   [0.4025199  0.50006896 0.3352405 ]\n",
            "   [0.3860026  0.49188495 0.3232575 ]\n",
            "   [0.39858878 0.50214267 0.3506721 ]]\n",
            "\n",
            "  [[0.87815756 0.87815756 0.834285  ]\n",
            "   [0.9248162  0.9208946  0.9012868 ]\n",
            "   [0.91821957 0.914298   0.89469016]\n",
            "   ...\n",
            "   [0.3741192  0.46799174 0.32681525]\n",
            "   [0.3639955  0.47208372 0.3130151 ]\n",
            "   [0.37960324 0.4847503  0.33247933]]]], shape=(32, 64, 64, 3), dtype=float32)\n",
            "tf.Tensor([1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 0], shape=(32,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 딥러닝 모델 만들기\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(64, 64, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    tf.keras.layers.Dropout(0.2), # overfitting 완화 -> dropout 레이어 - 윗레이어 노드를 일부 제거\n",
        "    \n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2), # overfitting 완화 -> dropout 레이어 - 윗레이어 노드를 일부 제거\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid') # binary crossentropy는 마지막 sigmoid 필요\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=5)\n",
        "# train_ds ((이미지들), (정답들)) 형태\n",
        "    \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6mmSz3O8p3U",
        "outputId": "c8a5e287-6628-48b9-e91a-b16b31640d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 32, 32, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 128)       36992     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 16, 16, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               4194432   \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,232,449\n",
            "Trainable params: 4,232,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "576/625 [==========================>...] - ETA: 19s - loss: 0.6390 - accuracy: 0.6227"
          ]
        }
      ]
    }
  ]
}